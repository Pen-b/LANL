{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LANL competition](https://www.kaggle.com/c/LANL-Earthquake-Prediction)\n",
    "- [introduction](https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/77525)\n",
    "- [Benchmark analysis](https://www.kaggle.com/inversion/basic-feature-benchmark/notebook)\n",
    "- [good EDA and discussion + comments](https://www.kaggle.com/allunia/shaking-earth/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:\\\\LANL\\\\all' # windows\n",
    "root = '/media/ben/data/kaggle/LANL/' # linux\n",
    "\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load 9GB csv\n",
    "# train = pd.read_csv(os.path.join(root,'train.csv'), dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure sequences\n",
    "There are 16 failures in the data set, but the time-to-fail only ever reaches very small decimals.<br>\n",
    "The last rows do *NOT* end in a failure. \n",
    "\n",
    "- when loading the data..\n",
    "- Lets, use the time difference to identify where the T2F jumps back up and mark these as failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train = pd.read_hdf(os.path.join(root,'{}_train.hdf'.format(version)),'mydata')\n",
    "except:\n",
    "    # load in as chunks\n",
    "    chunksize = 10 ** 6\n",
    "    chunks = list()\n",
    "    sequenceNumber = 0 # first failure sequence\n",
    "    \n",
    "    for chunk in tqdm(pd.read_csv(os.path.join(root,'train.csv'),\n",
    "                             dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},\n",
    "                             chunksize=chunksize)):\n",
    "\n",
    "        chunk['seq'] = chunk['time_to_failure'].diff() # get time difference between each step\n",
    "        chunk['seq'] = (chunk['seq']>0).astype(float).copy() # float binary column where time_difference between steps is positive (i.e. reset after failure)\n",
    "        chunk['seq'].values[0] = sequenceNumber # set first as sequenceNumber\n",
    "        chunk['seq'] = chunk['seq'].cumsum().copy() # sum up sequence values\n",
    "        chunks.append(chunk) # append results to list\n",
    "        sequenceNumber = chunk['seq'].values[-1] # get latest sequnce number\n",
    "        \n",
    "    # concat chunks & save\n",
    "    train = pd.concat(chunks)\n",
    "    print('Out:{}'.format(len(train)))\n",
    "    train.to_hdf(os.path.join(root,'{}_train.hdf'.format(version)),'mydata',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas doesn't show us all the decimals\n",
    "pd.options.display.precision = 15\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check our sequnces worked on a known failure point\n",
    "train['seq'][5600000:5700000].astype(float).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.arange(0,17,1)\n",
    "sequenceDict = dict()\n",
    "for seq in sequences:\n",
    "    sequenceDict[seq] = train.loc[train['seq']==seq].reset_index(drop=True)\n",
    "    print('Seq:{}, {}'.format(seq, len(sequenceDict[seq])), end='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Prep\n",
    "\n",
    "1. There are 150,000 rows in each test segment. \n",
    "2. The training data is reduced from 6 millions rows to summary features every 150,000 rows. (~5000 summary rows).\n",
    "3. Lets use our sequenceFailure data to avoid summarising over failure points e.g. (5,4,3,2,1,0,5,4,3,2,1) \n",
    "\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sequenceDict[0]\n",
    "test1 = test[-150000:]\n",
    "x = test1['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceSegments(sequenceDF,rows):\n",
    "    segments = int(np.floor(sequenceDF.shape[0] / rows))\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSequenceSegments(test,150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(sequenceDF,seqID,getY=bool):\n",
    "    acoustics = sequenceDF['acoustic_data'].copy()\n",
    "    x = acoustics.values\n",
    "    \n",
    "    X_train = pd.DataFrame({'segID':seqID,\n",
    "                            'ave':x.mean(),\n",
    "                            'std':x.std(),\n",
    "                            'max':x.max(),\n",
    "                            'min':x.min(),\n",
    "                            'total':abs(x).sum(), # total abs acoustic\n",
    "                            'PoT':len(x[(x >= x.mean()+x.std()) | (x <= x.mean()-x.std())])/len(x), # peaks over/under threshold (1*std)\n",
    "                            'meanDiff':acoustics.diff().mean(), # change per step [max, median]\n",
    "                            'stdDiff':acoustics.diff().std(), #  change per step [max, median]\n",
    "                            'maxDiff':acoustics.diff().max(), #  change per step [max, median]\n",
    "                            'Q001Diff':np.quantile(x,0.001), # Quantile\n",
    "                            'Q01Diff':np.quantile(x,0.01), # Quantile\n",
    "                            'Q05Diff':np.quantile(x,0.05), # Quantile\n",
    "                            'Q10Diff':np.quantile(x,0.10), # Quantile\n",
    "                            'Q999Diff':np.quantile(x,0.999), # Quantile\n",
    "                            'Q99Diff':np.quantile(x,0.99), # Quantile\n",
    "                            'Q95Diff':np.quantile(x,0.95), # Quantile\n",
    "                            'Q90Diff':np.quantile(x,0.90), # Quantile\n",
    "                            'Qrng5-95':np.subtract(*np.percentile(x, [95, 5])) # Quartile Range from 0.05 to 0.95% (range of values)\n",
    "                           },index=[0])\n",
    "    \n",
    "    # IF so that we can re-use this later and not pass any y's\n",
    "    if getY == True:\n",
    "        y = sequenceDF['time_to_failure'].values[-1]\n",
    "        y_train = pd.DataFrame({'segID':seqID,\n",
    "                                'time_to_failure':y},index=[0])\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFeatures(test1,99,getY=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [10,5000,20000,]:\n",
    "#     x.rolling(window=r,min_periods=r).mean().plot()\n",
    "    \n",
    "# plt.plot(x.index, [x.mean()]*len(x))\n",
    "# plt.plot(x.index, [x.mean()+x.std()]*len(x))\n",
    "# plt.plot(x.index, [x.mean()-x.std()]*len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training file with simple derived features\n",
    "X = list()\n",
    "y = list()\n",
    "rows = 150000\n",
    "segID = 0\n",
    "\n",
    "for seq in sequences:\n",
    "    print(seq, end=',')\n",
    "    sequenceDF = sequenceDict[seq].copy() # take copy of entire failure sequence\n",
    "    nSegments = getSequenceSegments(sequenceDF,rows) # get number of 150,000 row segments per sequence\n",
    "    \n",
    "    for segment in range(nSegments):\n",
    "        segDF = sequenceDF.iloc[segment*rows:segment*rows+rows].copy()\n",
    "        xDF,yDF = getFeatures(segDF,segID,getY=True)\n",
    "        segID+=1\n",
    "        X.append(xDF)\n",
    "        y.append(yDF)\n",
    "    \n",
    "#     # manually add the last 150,000 to capture failure\n",
    "#     segDF = sequenceDF[-rows:].copy()\n",
    "#     xDF,yDF = getFeatures(segDF,segID)\n",
    "#     segID+=1\n",
    "#     X.append(xDF)\n",
    "#     y.append(yDF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X,sort=False).reset_index(drop=True)\n",
    "y_train = pd.concat(y,sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Predict & Score\n",
    " - [notes on feature scaling](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAEscorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "models = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NuSVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca',PCA()),\n",
    "                 ('model', NuSVR())])\n",
    "\n",
    "params = {'pca__n_components': [2,4,8,16],\n",
    "          'model__kernel':['rbf'],\n",
    "          'model__nu': [0.5,0.75,0.9],\n",
    "          'model__C': [1,2,2.5],\n",
    "          'model__gamma': ['auto'],\n",
    "          }\n",
    "\n",
    "gs_NuSVR = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        scoring=MAEscorer,\n",
    "                        n_jobs=-1,\n",
    "                        cv=3)\n",
    "\n",
    "%time gs_NuSVR = gs_NuSVR.fit(X_train.iloc[:,1:], y_train.iloc[:,1].values.flatten())\n",
    "print('\\n',gs_NuSVR.best_score_,'\\n', gs_NuSVR.best_params_,)\n",
    "models.append(gs_NuSVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [XGBRegressor](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca',PCA()),\n",
    "                 ('model', XGBRegressor())])\n",
    "\n",
    "params = {'pca__n_components': [2,4,8,16],\n",
    "          'model__max_depth':[3,4,5,],\n",
    "          'model__learning_rate ': [0.001,0.01,0.1],\n",
    "          'model__n_estimators': [75,100,125],}\n",
    "\n",
    "gs_XGB = GridSearchCV(estimator=pipe,\n",
    "                      param_grid=params,\n",
    "                      scoring=MAEscorer,\n",
    "                      n_jobs=-1,\n",
    "                      cv=3)\n",
    "\n",
    "%time gs_XGB = gs_XGB.fit(X_train.iloc[:,1:], y_train.iloc[:,1].values.flatten())\n",
    "print('\\n',gs_XGB.best_score_,'\\n', gs_XGB.best_params_,)\n",
    "models.append(gs_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results and [Residuals](http://blog.minitab.com/blog/adventures-in-statistics-2/why-you-need-to-check-your-residual-plots-for-regression-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(axis,model,title):\n",
    "    global X_train,y_train\n",
    "    y_act = y_train.iloc[:,1].values.flatten()\n",
    "    y_pred = model.best_estimator_.predict(X_train.iloc[:,1:])\n",
    "    score = mean_absolute_error(y_act, y_pred)\n",
    "    \n",
    "    axis.set_title('{}: {:.3f}'.format(title,score))\n",
    "    axis.scatter(y_act,y_pred, s=0.5,color='blue')\n",
    "    axis.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)], lw=2,color='black')\n",
    "    axis.set_xlim(0,20)\n",
    "    axis.set_ylim(0,20)\n",
    "    axis.set_xlabel('actual', fontsize=12)\n",
    "    axis.set_ylabel('predicted', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResidual(axis,model,title):\n",
    "    global X_train,y_train\n",
    "    y_act = y_train.iloc[:,1].values.flatten()\n",
    "    y_pred = model.best_estimator_.predict(X_train.iloc[:,1:])\n",
    "    residuals = y_act - y_pred\n",
    "    \n",
    "    axis.set_title('Residuals')\n",
    "    axis.scatter(y_pred,residuals,s=0.5,color='blue')\n",
    "    axis.plot([0,20], [0,0], lw=2,color='black')\n",
    "    axis.set_xlim(0,20)\n",
    "    axis.set_ylim(-15,15)\n",
    "    axis.set_xlabel('predicted', fontsize=12)\n",
    "    axis.set_ylabel('residual', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(10,10), sharex=True)\n",
    "\n",
    "for e,(mod,nm) in enumerate(zip([gs_NuSVR,gs_XGB],['gs_NuSVR','gs_XGB'])):\n",
    "    plotResults(axs[e,0],mod,nm)\n",
    "    plotResidual(axs[e,1],mod,nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data and Write Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root,'sample_submission.csv'), index_col='seg_id')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list()\n",
    "for seg_id in tqdm(submission.index):\n",
    "    seg = pd.read_csv(os.path.join(root,os.path.join('test',seg_id))+ '.csv')\n",
    "    X_test.append(getFeatures(seg,seg_id,getY=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat(X_test).set_index(keys='segID',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = gs_XGB.predict(X_test)\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(root,'{}.1_submission.csv'.format(version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

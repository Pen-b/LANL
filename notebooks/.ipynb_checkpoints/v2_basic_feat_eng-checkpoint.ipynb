{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LANL competition](https://www.kaggle.com/c/LANL-Earthquake-Prediction)\n",
    "- [introduction](https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/77525)\n",
    "- [Benchmark analysis](https://www.kaggle.com/inversion/basic-feature-benchmark/notebook)\n",
    "- [good EDA and discussion + comments](https://www.kaggle.com/allunia/shaking-earth/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:\\\\LANL\\\\all' # windows\n",
    "#root = '/media/ben/data/kaggle/LANL/' # linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load 9GB csv\n",
    "# train = pd.read_csv(os.path.join(root,'train.csv'), dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train = pd.read_hdf(os.path.join(root,'trainx_{}.hdf'.format(version)),'mydata')\n",
    "except:\n",
    "    # load in as chunks\n",
    "    chunksize = 10 ** 6\n",
    "    chunks = list()\n",
    "    sequenceNumber = 0 # first failure sequence\n",
    "    \n",
    "    for chunk in tqdm(pd.read_csv(os.path.join(root,'train.csv'),\n",
    "                             dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},\n",
    "                             chunksize=chunksize)):\n",
    "\n",
    "        chunk['seq'] = chunk['time_to_failure'].diff() # get time difference between each step\n",
    "        chunk['seq'] = (chunk['seq']>0).astype(int).copy() # binary column where time_difference between steps is positive (i.e. reset after failure)\n",
    "        chunk['seq'].values[0] = sequenceNumber # set first as sequenceNumber\n",
    "        chunk['seq'] = chunk['seq'].cumsum().astype(float).copy()\n",
    "        chunks.append(chunk)\n",
    "        sequenceNumber = chunk['seq'].values[-1]\n",
    "        \n",
    "    # concat chunks & save\n",
    "    train = pd.concat(chunks)\n",
    "    print('Out:{}'.format(len(train)))\n",
    "    train.to_hdf(os.path.join(root,'train_{}.hdf'.format(version)),'mydata',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas doesn't show us all the decimals\n",
    "pd.options.display.precision = 15\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failures\n",
    "There are several failures in the data set, but the time-to-fail only ever reaches very small decimals. Lets, use the time difference to identify where the T2F jumps back up and mark these as failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    chunk['seq'] = chunk['seq'].astype(float).copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat(chunks)\n",
    "print('Out:{}'.format(len(train)))\n",
    "train.to_hdf(os.path.join(root,'train_{}.hdf'.format(version)),'mydata',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [x for x in range(0,17)]:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['seq'][5600000:5700000].astype(float).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['seq'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['seq']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = list()\n",
    "for chunk in np.array_split(train,10000):\n",
    "    chunk['tdiff'] = (chunk['tdiff']>0).astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['failSeq'] = np.nan # short for Failure Sequence\n",
    "start = 0\n",
    "sequences = list()\n",
    "\n",
    "for seq_num,end in enumerate(train.loc[train['tdiff']>0].index.values):\n",
    "    train.iloc[start:end,3] = seq_num\n",
    "    print('Sequence:{}, start={}, end={}'.format(seq_num,start,end))\n",
    "    start=end\n",
    "    sequences.append(seq_num)\n",
    "train.iloc[start:,3] = seq_num+1 # and the last one\n",
    "print('Sequence:{}, start={}, end={}'.format(seq_num+1,start,len(train)))\n",
    "sequences.append(seq_num+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just check thats all working\n",
    "#train[5656570:5656580]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of data points per failure in millions\n",
    "(train['failSeq'].value_counts()/1000000).sort_index().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative acoustic data to failure\n",
    "train['cumsum'] = train.groupby(['failSeq'])['acoustic_data'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [1000,10000]\n",
    "for r in ranges:\n",
    "    label = 'n{}k_mean'.format(int(r/1000))\n",
    "    train[label] = np.nan\n",
    "    \n",
    "    for seq in sequences:\n",
    "        print(label,seq)\n",
    "        train.loc[train['failSeq']==seq,label] = train.loc[train['failSeq']==seq,'acoustic_data'].rolling(window=r,min_periods=1).mean()\n",
    "        \n",
    "    #train[label] = train.groupby(['failSeq'])['acoustic_data'].rolling(window=r).mean() ## this uses lots of memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Prep\n",
    "\n",
    "1. There are 150,000 rows in each test segment. \n",
    "2. The training data is reduced from 6 millions rows to summary features every 150,000 rows. (~5000 summary rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2,figsize=(25, 4))\n",
    "\n",
    "\n",
    "#axs[0].set_xlim(0,n+1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training file with simple derived features\n",
    "rows = 150_000\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "\n",
    "X_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['ave', 'std', 'max', 'min'])\n",
    "y_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['time_to_failure'])\n",
    "\n",
    "for segment in tqdm(range(segments)):\n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    \n",
    "    y_train.loc[segment, 'time_to_failure'] = y\n",
    "    \n",
    "    X_train.loc[segment, 'ave'] = x.mean()\n",
    "    X_train.loc[segment, 'std'] = x.std()\n",
    "    X_train.loc[segment, 'max'] = x.max()\n",
    "    X_train.loc[segment, 'min'] = x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Predict & Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = NuSVR()\n",
    "svm.fit(X_train_scaled, y_train.values.flatten())\n",
    "y_pred = svm.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_train.values.flatten(), y_pred)\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlabel('actual', fontsize=12)\n",
    "plt.ylabel('predicted', fontsize=12)\n",
    "plt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_absolute_error(y_train.values.flatten(), y_pred)\n",
    "print(f'Score: {score:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data and Write Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root,'sample_submission.csv'), index_col='seg_id')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg_id in tqdm(X_test.index[:]):\n",
    "    seg = pd.read_csv(os.path.join(root,os.path.join('test',seg_id))+ '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "\n",
    "    X_test.loc[seg_id, 'ave'] = x.mean()\n",
    "    X_test.loc[seg_id, 'std'] = x.std()\n",
    "    X_test.loc[seg_id, 'max'] = x.max()\n",
    "    X_test.loc[seg_id, 'min'] = x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "submission['time_to_failure'] = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(root,'{}_submission.csv'.format(version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LANL competition](https://www.kaggle.com/c/LANL-Earthquake-Prediction)\n",
    "- [introduction](https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/77525)\n",
    "- [Benchmark analysis](https://www.kaggle.com/inversion/basic-feature-benchmark/notebook)\n",
    "- [good EDA and discussion + comments](https://www.kaggle.com/allunia/shaking-earth/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ben/github/LANL/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:\\\\LANL\\\\all' # windows\n",
    "root = '/media/ben/data/kaggle/LANL/' # linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load 9GB csv\n",
    "# train = pd.read_csv(os.path.join(root,'train.csv'), dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in chunks\n",
    "# chunksize = 10 ** 6\n",
    "# chunks = list()\n",
    "\n",
    "# for chunk in tqdm(pd.read_csv(os.path.join(root,'train.csv'),\n",
    "#                          dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},\n",
    "#                          chunksize=chunksize)):\n",
    "#     chunks.append(chunk)\n",
    "    \n",
    "# # concat chunks\n",
    "# train = pd.concat(chunks)\n",
    "# len(train)\n",
    "\n",
    "# # save as hdf\n",
    "# train.to_hdf(os.path.join(root,'train.hdf'),'mydata',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf(os.path.join(root,'train.hdf'),'mydata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1.4690999832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.4690999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.4690999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.4690999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.4690999788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure\n",
       "0             12     1.4690999832\n",
       "1              6     1.4690999821\n",
       "2              8     1.4690999810\n",
       "3              5     1.4690999799\n",
       "4              8     1.4690999788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas doesn't show us all the decimals\n",
    "pd.options.display.precision = 15\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failures\n",
    "There are several failures in the data set, but the time-to-fail only ever reaches very small decimals. Lets, use the time difference to identify where the T2F jumps back up and mark these as failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time difference between each step\n",
    "train['tdiff'] = train['time_to_failure'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:0, start=0, end=5656574\n",
      "Sequence:1, start=5656574, end=50085878\n",
      "Sequence:2, start=50085878, end=104677356\n",
      "Sequence:3, start=104677356, end=138772453\n",
      "Sequence:4, start=138772453, end=187641820\n",
      "Sequence:5, start=187641820, end=218652630\n",
      "Sequence:6, start=218652630, end=245829585\n",
      "Sequence:7, start=245829585, end=307838917\n",
      "Sequence:8, start=307838917, end=338276287\n",
      "Sequence:9, start=338276287, end=375377848\n",
      "Sequence:10, start=375377848, end=419368880\n",
      "Sequence:11, start=419368880, end=461811623\n",
      "Sequence:12, start=461811623, end=495800225\n",
      "Sequence:13, start=495800225, end=528777115\n",
      "Sequence:14, start=528777115, end=585568144\n",
      "Sequence:15, start=585568144, end=621985673\n",
      "Sequence:16, start=621985673, end=629145480\n"
     ]
    }
   ],
   "source": [
    "train['failSeq'] = np.nan # short for Failure Sequence\n",
    "start = 0\n",
    "sequences = list()\n",
    "\n",
    "for seq_num,end in enumerate(train.loc[train['tdiff']>0].index.values):\n",
    "    train.iloc[start:end,3] = seq_num\n",
    "    print('Sequence:{}, start={}, end={}'.format(seq_num,start,end))\n",
    "    start=end\n",
    "    sequences.append(seq_num)\n",
    "train.iloc[start:,3] = seq_num+1 # and the last one\n",
    "print('Sequence:{}, start={}, end={}'.format(seq_num+1,start,len(train)))\n",
    "sequences.append(seq_num+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just check thats all working\n",
    "#train[5656570:5656580]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFLFJREFUeJzt3X2UXHV9x/H3l0QQUB4CS4hEjMUo2MMh4hZptT6AD0FUaItFbWXLSZtaUWy1R9PaU2lrbbTHh7Y+NTVqtD4hiiA+AQHUtkpZHiTogkBESMFktYCPRwt++8e9OSzLLjP37p3s5Jf365w5c+fOne98793Zz/7m7r0zkZlIknZ+u813A5KkbhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIs3JFPduCBB+ayZct25FNK0k7vyiuv/H5mjvRabocG+rJlyxgfH9+RTylJO72I+G4/y7nLRZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklSIHXpikdTWWWed1ckyUskcoUtSIQx0SSqEgS5Jhegr0CNiv4g4JyKuj4iJiPj1iFgUERdFxI319f6DblaSNLt+R+j/BHwxMw8HjgImgDXAxsxcDmysb0uS5knPQI+IfYCnAusBMvMXmXkXcBKwoV5sA3DyoJqUJPXWzwj9V4BJ4AMRcXVEvC8i9gYWZ+YdAPX1QTM9OCJWR8R4RIxPTk521rgk6f76CfSFwNHAezLzCcBPaLB7JTPXZeZoZo6OjPT8wg1JUkv9BPoWYEtmXl7fPocq4LdGxBKA+nrbYFqUJPWjZ6Bn5veA2yLicfWs44FvAecDY/W8MeC8gXQoSepLv6f+vxL4SETsDmwGTqf6Y3B2RKwCbgVeOJgWJUn96CvQM/MaYHSGu47vth1JUlueKSpJhTDQJakQBrokFcJAl6RCGOiSVAi/sUhSESYOP6Kv5Y64fmLAncwfR+iSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEB62+CCO3HBkX8ttGts04E4kqTdH6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiH6+iyXiLgF+BFwL3BPZo5GxCLgE8Ay4BbgdzPzzsG0KUnqpckI/RmZuSIzR+vba4CNmbkc2FjfliTNk7nscjkJ2FBPbwBOnns7kqS2+g30BC6MiCsjYnU9b3Fm3gFQXx80iAYlSf3p9/PQn5yZt0fEQcBFEXF9v09Q/wFYDXDooYe2aFGS1I++RuiZeXt9vQ04FzgG2BoRSwDq622zPHZdZo5m5ujIyEg3XUuSHqBnoEfE3hHx8O3TwLOB64DzgbF6sTHgvEE1KUnqrZ9dLouBcyNi+/IfzcwvRsQVwNkRsQq4FXjh4NrUTN71skt6LnPGe4/bAZ1IGgY9Az0zNwNHzTD/B8Dxg2hKktScZ4pKUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVot9vLNo5nLVvn8vdPdg+JGkeOEKXpEKUNUKXCrBszef6Wu6WtScOuBPtbByhS1IhDHRJKoSBLkmFMNAlqRD+U1QqmP9g3bU4QpekQhjoklQIA12SCmGgS1Ih+g70iFgQEVdHxAX17UdHxOURcWNEfCIidh9cm5KkXpqM0F8FTEy5/Wbg7Zm5HLgTWNVlY5KkZvoK9IhYCpwIvK++HcBxwDn1IhuAkwfRoCSpP/2O0N8BvBb4ZX37AOCuzLynvr0FOGSmB0bE6ogYj4jxycnJOTUrSZpdz0CPiOcB2zLzyqmzZ1g0Z3p8Zq7LzNHMHB0ZGWnZpiSpl37OFH0y8IKIeC7wUGAfqhH7fhGxsB6lLwVuH1ybkqReeo7QM/MvMnNpZi4DXgRckpm/B1wKnFIvNgacN7AuJUk9zeU49NcBr46Im6j2qa/vpiVJUhuNPpwrMy8DLqunNwPHdN+SJKkNzxSVpEIY6JJUCANdkgphoEtSIfzGImmODr70mr6W+94zVgy4E+3qHKFLUiEcoUvSDN71skv6Wu6M9x434E765whdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCeBz6DjRx+BF9LXfE9RMD7kRq6ax9+1zu7sH2oRk5QpekQhjoklQId7lImjdHbjiyr+U2jW0acCdlcIQuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCtHzsMWIeCjwFWCPevlzMvMNEfFo4OPAIuAq4KWZ+YtBNqvBeeupz+trudd84oIBdyKprX5G6D8HjsvMo4AVwMqIOBZ4M/D2zFwO3AmsGlybkqReeo7QMzOBH9c3H1JfEjgOeEk9fwNwFvCe7luUurXxksP6Wu74424ecCdSt/rahx4RCyLiGmAbcBFwM3BXZt5TL7IFOGSWx66OiPGIGJ+cnOyiZ0nSDPoK9My8NzNXAEuBY4CZPjYwZ3nsuswczczRkZGR9p1Kkh5Uo6NcMvMu4DLgWGC/iNi+y2YpcHu3rUmSmugZ6BExEhH71dN7As8EJoBLgVPqxcaA8wbVpCSpt34+bXEJsCEiFlD9ATg7My+IiG8BH4+INwJXA+sH2KckqYd+jnK5FnjCDPM3U+1PlyQNAc8UlaRCGOiSVAgDXZIKYaBLUiH8TlENxJY1X+1ruaVrf3PAnUi7DkfoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiF6BnpEPDIiLo2IiYj4ZkS8qp6/KCIuiogb6+v9B9+uJGk2/YzQ7wFek5lHAMcCZ0TE44E1wMbMXA5srG9LkuZJz0DPzDsy86p6+kfABHAIcBKwoV5sA3DyoJqUJPXWaB96RCwDngBcDizOzDugCn3goK6bkyT1r+9Aj4iHAZ8C/jQzf9jgcasjYjwixicnJ9v0KEnqQ1+BHhEPoQrzj2Tmp+vZWyNiSX3/EmDbTI/NzHWZOZqZoyMjI130LEmaQT9HuQSwHpjIzLdNuet8YKyeHgPO6749SVK/FvaxzJOBlwKbIuKaet5fAmuBsyNiFXAr8MLBtChJ6kfPQM/M/wBilruP77YdSVJbnikqSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYXoGegR8f6I2BYR102ZtygiLoqIG+vr/QfbpiSpl35G6B8EVk6btwbYmJnLgY31bUnSPOoZ6Jn5FeB/p80+CdhQT28ATu64L0lSQ233oS/OzDsA6uuDZlswIlZHxHhEjE9OTrZ8OklSLwP/p2hmrsvM0cwcHRkZGfTTSdIuq22gb42IJQD19bbuWpIktdE20M8HxurpMeC8btqRJLXVz2GLHwO+BjwuIrZExCpgLfCsiLgReFZ9W5I0jxb2WiAzXzzLXcd33IskaQ48U1SSCmGgS1IhDHRJKoSBLkmF6PlPUUnS3L311Of1tdxrPnFB6+dwhC5JhTDQJakQBrokFcJAl6RCzPs/RZet+Vxfy92y9sQBdyJJOzdH6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEHMK9IhYGRE3RMRNEbGmq6YkSc21DvSIWAC8CzgBeDzw4oh4fFeNSZKamcsI/RjgpszcnJm/AD4OnNRNW5KkpuYS6IcAt025vaWeJ0maB5GZ7R4Y8ULgOZn5h/XtlwLHZOYrpy23Glhd33wccEMf5Q8Evt+qscHWGvZ6w9zbsNcb5t66rjfMvXVdb5h7a1LvUZk50muhuXyn6BbgkVNuLwVun75QZq4D1jUpHBHjmTk6h94GUmvY6w1zb8Neb5h767reMPfWdb1h7m0Q9eayy+UKYHlEPDoidgdeBJzfTVuSpKZaj9Az856IeAXwJWAB8P7M/GZnnUmSGpnLLhcy8/PA5zvqZapGu2h2YK1hrzfMvQ17vWHuret6w9xb1/WGubfO67X+p6gkabh46r8kFcJAl6RCGOiSVIg5/VO0SxGxCMjMvHO+e5kuIhZTnQWbwO2ZuXWO9Tpd1y7rDWBdO6vXdW91zaHddlJT8/pP0Yg4FHgLcDxwFxDAPsAlwJrMvKVl3U5+sSJiBfBeYF/gf+rZS+teX56ZVzWo1em6DqBeZ+vadb0B9DbU266uuS+wkimvY+BLmXlXi1qHU33O0tRa52fmRNNaA6rX2bp2XW/Yt90DZOa8XYCvAacCC6bMW0B1ktLXW9RbAXwdmAAuri/X1/OOblHvGuBJM8w/FvjGPK9r1/U6W9cBbLuuexv2bXcacDPwHuCv6st763mnNaz1urq/NcDv15c12+e16K3rep2t66627WZ8ji6KtH5yuLHNfQ/ymK5/sR6sv5vmeV13ZL1G67qDt13XvQ3DtrsB2G+G+fsD325Y69vAQ2aYv3vLde26Xmfruqttu5ku870P/cqIeDewgfs+ufGRwBhwdYt6e2fm5dNnZubXI2LvFvW+EBGfAz40rb/TgC82rNX1unZdr8t17bpe170N+7YLqrfj0/2yvq+JXwKPAL47bf6S+r6muq7X5bp2XW/Yt90DzPc+9N2BVdy3TymofiE+C6zPzJ83rPfPwGHM/Iv1ncx8RYseT5jW3xaqfV6NzpAdwLp2Wq+u2cm6DqJex7WGettFxBjw18CF3Pc6PhR4FvB3mfnBBrVWAu8EbpxW6zHAKzKz0R+cAdTrbF27rjfs227G55jPQB+ErkNJmg8RsT/wHO7/Ov5StjgaJyJ2o/pCmqm1rsjMe1v21nW9zta163rDvu0eUH9YAz0inpeZF8x3H7OJiNVZfTRwF7U6XdcB1OtsXbuuN4DehnrbSQ9mmE8s+rUui9VftNFpyQ5rdbquA6jX5bp2Xa/r3oZ620VEl3+8Oh0wDaBetx9ctQtsu3kfoQ/8uMz7nuePM/NfW/Z3CHB5Zv54yvyVLfahHUN1EssV9RdqrwSu72p3UER8KDNP66jWU6jeGl6XmRe2ePyTgInM/GFE7El1eNbRwLeAN2Xm3Q1qnQmcm5m39Vy4v3rbP7//9sy8OCJeAvwG1eGu6zLz/1rUPAz4Lar/2dxDtZ/0Y03Ws8/neWJmXtlRrSWZeUcXtQZUr7N17bresG67+f6n6OuAF1N9wfSWevZSql+2j2fm2g6f6/TM/EDDx5wJnEH1i74CeFVmnlffd1VmHt2g1huAE6jOzr0IeBJwGfBMqv17f9+wt+lfJhLAM6hOjiEzX9Cw3n9n5jH19B9Rrfe5wLOBzzb9WUTEN4Gjsvrc/HXAT4FzqE7mOSozf7tBrbuBn1AdS/wx4JOZOdmkn2n1PkL1c9iL6uSfhwGfrnsjM/+gYb0zgecDXwaeS3X47J1UAf/yzLysba+au4g4KDO3zXcfM4mIAzLzB50V7OLYx7YXdsBxmVNq3triMZuAh9XTy4BxqlAHuLpFrQVUIfJDYJ96/p7AtS16uwr4d+DpwNPq6zvq6ae1qHf1lOkrgJF6em9gU4t6E1N7nXbfNU17o9o9+GxgPTBJdTjgGPDwFr1dW18vBLZSn2BE9Uexzc9i05QaewGX1dOHNn2d1I/bF1hLdVLcD+rLRD3vAcdYt70AX2jxmH2AfwA+DLxk2n3vblHvYKqTgN4FHACcVW/Ps4ElLeotmnY5ALiF6jj0RQ1rrZz2M1kPXAt8FFjcore1wIH19CiwGbiJ6jDGp3XxM53vfejbj8ucrtVxmRFx7SyXTcDiFv0tyHo3S1angz8dOCEi3kbzfaP3ZOa9mflT4ObM/GFd92e0OwZ1FLgSeD1wd1ajwJ9l5pcz88st6u0WEftHxAFU79wm6/5+QrULoanrIuL0evobETEKEBGPBZru0sjM/GVmXpiZq6heM++m2mW1uUVvu9W7XR5OFcD71vP3AB7Soh7c97lIe9R1ycxbW9Y7m2qE//TMPCAzD6B693Un8MkmhSLi6FkuT6R619nUB6he+58CXhQRn4qIPer7jm1R74NUu+FuAy4FfgacCHyV6gzPpr5P9Xux/TJOtcv0qnq6iTdNmX4r1YDp+VQDnsa7b4ETM3P7F0L/I3BqZj6G6pDKt7ao90Bd/bVvc6H6hbwJ+ALVN3esoxp53cSUv44N6m2lepE+atplGdX+0qb1LgFWTJu3kOo493sb1roc2Kue3m3aX/6rmvY25fFLqX7J30mLdyFT6txCFY7fqa8Pruc/jIYj6inr9UGq3SSXU4X4ZqrdEkc1rDXrKBfYs0Vvf1b38l3gTGAj8G9UI8M3tKj3KqqR2zqqUfXp9fwR4Cst6t3Q5r5Zlr+3fh1fOsPlZy16u2ba7dcD/0k1Em78Oub+7wxvfbDn6rPen9cZcuSUed9pWqd+3FWz9dKyt+uBhfX016fd1/hd8IzP0UWROTVQvZU+Fvgd4JR6ekHLWuuBp8xy30db1Fu6PdhmuO/JDWvtMcv8A6e++OawHU+k+mdj1z+fvYBHz+HxDweOAp5Ii7epdY3HDmC9HgE8op7er37tHTOHer9a1zi8g94uBF47dXtRvcN8HXBxw1rXActnue+2Fr1NMGVAUs8bA74JfLdFvW9MmX7jtPtahRz3DXLeVr/+NresswV4NfAaqgFATLmvza65V9Y/2+Oodi29A3gq8DfAh+f6usnM+T/KRdL91SfGrKE6+uugevZW4HxgbTY4QSYiTqEKxhtmuO/kzPxMw97eAlyYmRdPm78S+JfMXN6w3t8Cb8kpR5DV8x9Dta6nNKk3rcbzqd5BLMvMg1s8/g3TZr07Mycj4uC658ZHlEXE04E/AR5L9W7/NuAzwPszs82uzfvXN9ClnUebo7V2RK1hrVcfMntYZl63K2w7A13aiUTErZl56LDV2tXqDWtv8/1pi5KmiYhrZ7uLhkdrdVlrV6s3zL3NxkCXhs9iqg+Xmr6vPID/msdau1q9Ye5tRga6NHwuoDqh7Zrpd0TEZfNYa1erN8y9zch96JJUiPk+U1SS1BEDXZIKYaBLUiEMdEkqhIEuSYX4f5OrFPosrs+GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num of data points per failure in millions\n",
    "(train['failSeq'].value_counts()/1000000).sort_index().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative acoustic data to failure\n",
    "train['cumsum'] = train.groupby(['failSeq'])['acoustic_data'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1k_mean 0\n",
      "n1k_mean 1\n",
      "n1k_mean 2\n"
     ]
    }
   ],
   "source": [
    "ranges = [1000,10000]\n",
    "for r in ranges:\n",
    "    label = 'n{}k_mean'.format(int(r/1000))\n",
    "    train[label] = np.nan\n",
    "    \n",
    "    for seq in sequences:\n",
    "        print(label,seq)\n",
    "        train.loc[train['failSeq']==seq,label] = train.loc[train['failSeq']==seq,'acoustic_data'].rolling(window=r,min_periods=1).mean()\n",
    "        \n",
    "    #train[label] = train.groupby(['failSeq'])['acoustic_data'].rolling(window=r).mean() ## this uses lots of memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Prep\n",
    "\n",
    "1. reduces 6 millions rows to ~5000 by taking summary features every 150,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['failSeq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8,2,figsize=(25, 8))\n",
    "\n",
    "train[s:e]['acoustic_data'].plot(ax=axs[0])\n",
    "ax2=axs[0].twinx()\n",
    "train[s:e]['time_to_failure'].plot(ax=ax2);\n",
    "\n",
    "#axs[0].set_xlim(0,n+1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training file with simple derived features\n",
    "rows = 150_000\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "\n",
    "X_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['ave', 'std', 'max', 'min'])\n",
    "y_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "                       columns=['time_to_failure'])\n",
    "\n",
    "for segment in tqdm(range(segments)):\n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    \n",
    "    y_train.loc[segment, 'time_to_failure'] = y\n",
    "    \n",
    "    X_train.loc[segment, 'ave'] = x.mean()\n",
    "    X_train.loc[segment, 'std'] = x.std()\n",
    "    X_train.loc[segment, 'max'] = x.max()\n",
    "    X_train.loc[segment, 'min'] = x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Predict & Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = NuSVR()\n",
    "svm.fit(X_train_scaled, y_train.values.flatten())\n",
    "y_pred = svm.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_train.values.flatten(), y_pred)\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlabel('actual', fontsize=12)\n",
    "plt.ylabel('predicted', fontsize=12)\n",
    "plt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_absolute_error(y_train.values.flatten(), y_pred)\n",
    "print(f'Score: {score:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data and Write Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root,'sample_submission.csv'), index_col='seg_id')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg_id in tqdm(X_test.index[:]):\n",
    "    seg = pd.read_csv(os.path.join(root,os.path.join('test',seg_id))+ '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "\n",
    "    X_test.loc[seg_id, 'ave'] = x.mean()\n",
    "    X_test.loc[seg_id, 'std'] = x.std()\n",
    "    X_test.loc[seg_id, 'max'] = x.max()\n",
    "    X_test.loc[seg_id, 'min'] = x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "submission['time_to_failure'] = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(root,'{}_submission.csv'.format(version)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
